{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52556baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# set seed for reproducibility\n",
    "seed=99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18acd1ba",
   "metadata": {},
   "source": [
    "### Neural Network (NN)\n",
    "\n",
    "Neural Networks are \"black box\" models, meaning that it is often impossible to determine how exactly the models arrive at their predictions. This is because the networks process chunks of the training data one at a time and determine their own associations between the features and the result. This process can be controlled to a degree by manipulating the model layers, but there will still be an information gap when determining the exact relationships between variables. For a simple explanation of NNs, see AWS's [What is a Neural Network](https://aws.amazon.com/what-is/neural-network/#:~:text=A%20neural%20network%20is%20a,that%20resembles%20the%20human%20brain.).\n",
    "\n",
    "I will create a NN with the full dataset, the PCA dataset, and the combined feature dataset, since NNs are often better able to handle larger amounts of features. The data needs to be scaled with the `MinMaxScaler` to have all the data values bet ween 0 and 1. I will use the `Adam` optimizer and `binary-crossentropy` loss function since they are designed for binary classification tasks. Additionally, the final layer needs to have `sigmoid` activation so the model prediction will be binary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The Neural Network results are underwhelming. The model tends to reach its maximum accuracy in relatively few epochs, which is possibly due to the relatively small dataset (at least by NN standards), a lack of distinguishing features, or too much colinearity within the data. Given the necessary computational costs and iteration that is required for creating a NN model, the performance is far too poor to consider this method moving forward.\n",
    "\n",
    "I have tested all the machine learning modeling methods, but model performance is still far short of the target accuracy of 68%. Also, the similarity between the models means that there is no one model that stands out. The final method I will attempt is creating an Elo rating system, which is described in-depth below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d68eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to build the neural network model with a variable number of layers\n",
    "def create_model(num_layers=5, hidden_units=16, activation='relu', optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, input_dim=X_train.shape[1], activation=activation))\n",
    "    \n",
    "    for _ in range(num_layers - 1):  # Add additional hidden layers\n",
    "        model.add(Dense(hidden_units, activation=activation))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load your dataset and preprocess it (X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Create a KerasClassifier for use with GridSearchCV\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define hyperparameters and their possible values\n",
    "param_grid = {\n",
    "    'num_layers': [1, 2, 3],  # Try different numbers of layers\n",
    "    'hidden_units': [16, 32, 64],\n",
    "    'activation': ['relu', 'sigmoid'],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and their corresponding accuracy\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Test the best model on the test data\n",
    "best_model = grid_result.best_estimator_\n",
    "test_loss, test_accuracy = best_model.model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90850890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba560c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "stat_columns = team_full_20.loc[:,'a_FG':'h_TOVp'].columns\n",
    "\n",
    "X = team_full_20[stat_columns]\n",
    "y = team_full_20['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=seed)\n",
    "\n",
    "# scale the data\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
    "X_test_scaled = mm_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c6f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2957da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1af3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65535f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24196a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca624f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa94e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly set learning rate\n",
    "learning_rate = 0.001\n",
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # sigmoid activation for binary classification\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# set epochs and batch_size for model training\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "# train the model\n",
    "model.fit(X_train_pca, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model test score\n",
    "loss, accuracy = model.evaluate(X_test_pca, y_test, verbose=0)\n",
    "# add model results to the results_df for comparison\n",
    "nn_results = {'model_name': 'nn_pca', 'cv_score': None, 'gs_score': None, 'train_score': None, 'test_score': accuracy}\n",
    "results_df = results_df.append(nn_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c9a4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b38718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined dataset\n",
    "X = team_full_20_combined\n",
    "y = team_factor_20['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=seed)\n",
    "\n",
    "# scale the data\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
    "X_test_scaled = mm_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37513a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined dataset PCA\n",
    "X = team_full_20_combined[best_selected_feature_names]\n",
    "y = team_factor_20['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=seed)\n",
    "\n",
    "# scale the data\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
    "X_test_scaled = mm_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fd62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly set learning rate\n",
    "learning_rate = 0.001\n",
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # sigmoid activation for binary classification\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# set epochs and batch_size for model training\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "# train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate model test score\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "# add model results to the results_df for comparison\n",
    "nn_results = {'model_name': 'nn_full', 'cv_score': None, 'gs_score': None, 'train_score': None, 'test_score': accuracy}\n",
    "results_df = results_df.append(nn_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a35ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbaenv",
   "language": "python",
   "name": "nbaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
